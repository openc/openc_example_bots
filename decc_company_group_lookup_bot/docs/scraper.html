<!DOCTYPE html>

<html>
<head>
  <title>scraper.rb</title>
  <meta http-equiv="content-type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width, target-densitydpi=160dpi, initial-scale=1.0; maximum-scale=1.0; user-scalable=0;">
  <link rel="stylesheet" media="all" href="docco.css" />
</head>
<body>
  <div id="container">
    <div id="background"></div>
    
    <ul class="sections">
        
          <li id="title">
              <div class="annotation">
                  <h1>scraper.rb</h1>
              </div>
          </li>
        
        
        
        <li id="section-1">
            <div class="annotation">
              
              <div class="pilwrap ">
                <a class="pilcrow" href="#section-1">&#182;</a>
              </div>
              <h2 id="prerequisites">Prerequisites</h2>

            </div>
            
        </li>
        
        
        <li id="section-2">
            <div class="annotation">
              
              <div class="pilwrap ">
                <a class="pilcrow" href="#section-2">&#182;</a>
              </div>
              <p>You need to load any gems for your scraper at the top of the
file. Here we’ll be using <code>json</code> for output, <code>mechanize</code> to fetch
pages and <code>nokogiri</code> to parse and query the HTML</p>

            </div>
            
            <div class="content"><div class='highlight'><pre><span class="hljs-keyword">require</span> <span class="hljs-string">'json'</span>
<span class="hljs-keyword">require</span> <span class="hljs-string">'mechanize'</span>
<span class="hljs-keyword">require</span> <span class="hljs-string">'nokogiri'</span></pre></div></div>
            
        </li>
        
        
        <li id="section-3">
            <div class="annotation">
              
              <div class="pilwrap ">
                <a class="pilcrow" href="#section-3">&#182;</a>
              </div>
              <h2 id="setup">Setup</h2>

            </div>
            
        </li>
        
        
        <li id="section-4">
            <div class="annotation">
              
              <div class="pilwrap ">
                <a class="pilcrow" href="#section-4">&#182;</a>
              </div>
              <p>We’ll setup a few variables here to make the code easier to
edit and reuse. <code>SOURCE_URL</code> is the page we want to scrape, 
and the <code>agent</code> variable is setting up Mechanize which is like
a mini web browser. It will fetch the page and handle things like
redirects and https for us, returning the HTML source as a string.</p>

            </div>
            
            <div class="content"><div class='highlight'><pre><span class="hljs-constant">SOURCE_URL</span> = <span class="hljs-string">"https://www.og.decc.gov.uk/eng/fox/decc/PED301X/companyLookup"</span>
agent = <span class="hljs-constant">Mechanize</span>.new
agent.user_agent_alias = <span class="hljs-string">'Mac Safari'</span></pre></div></div>
            
        </li>
        
        
        <li id="section-5">
            <div class="annotation">
              
              <div class="pilwrap ">
                <a class="pilcrow" href="#section-5">&#182;</a>
              </div>
              <h2 id="fetching-the-page">Fetching the page</h2>

            </div>
            
        </li>
        
        
        <li id="section-6">
            <div class="annotation">
              
              <div class="pilwrap ">
                <a class="pilcrow" href="#section-6">&#182;</a>
              </div>
              <p><code>agent.get</code> tells Mechanize to retrieve the page for whichever url
we pass as an argument. This returns a string containing the HTML source 
of the page</p>
<p><code>Nokogiri.parse</code> changes this string into a Ruby object which we can search
with CSS or XPath selectors (just like the ones in jQuery)</p>

            </div>
            
            <div class="content"><div class='highlight'><pre>page = agent.get(<span class="hljs-constant">SOURCE_URL</span>)
doc = <span class="hljs-constant">Nokogiri</span>.parse(page.body)</pre></div></div>
            
        </li>
        
        
        <li id="section-7">
            <div class="annotation">
              
              <div class="pilwrap ">
                <a class="pilcrow" href="#section-7">&#182;</a>
              </div>
              <h2 id="extracting-the-data">Extracting the data</h2>

            </div>
            
        </li>
        
        
        <li id="section-8">
            <div class="annotation">
              
              <div class="pilwrap ">
                <a class="pilcrow" href="#section-8">&#182;</a>
              </div>
              <p>In this page, the data we want is in an HTML table with a class <code>.setoutList</code>
<em>WATCH OUT</em> because CSS queries in Nokogiri are case sensitive</p>
<p>We’ll pull out all the rows from the table and put their <code>td</code> cells into an array.
To keep things simple we’ll setup our empty array to capture the output and we should
end up with an array of arrays, one for each row of the table.</p>

            </div>
            
            <div class="content"><div class='highlight'><pre>output = []
doc.css(<span class="hljs-string">'.setoutList tr'</span>).each <span class="hljs-keyword">do</span> |row| 
  output &lt;&lt; row.css(<span class="hljs-string">'td'</span>).map {|r| r.text }
<span class="hljs-keyword">end</span></pre></div></div>
            
        </li>
        
        
        <li id="section-9">
            <div class="annotation">
              
              <div class="pilwrap ">
                <a class="pilcrow" href="#section-9">&#182;</a>
              </div>
              <h2 id="outputting-the-data">Outputting the data</h2>

            </div>
            
        </li>
        
        
        <li id="section-10">
            <div class="annotation">
              
              <div class="pilwrap ">
                <a class="pilcrow" href="#section-10">&#182;</a>
              </div>
              <p>The OpenCorporates Turbot system is very simple and only requires you
to output some JSON for each record you capture.
Here we’ll go through the output rows and make a Ruby Hash with the hash keys becoming the
field names. In this scraper it’s very simple as there are only two columns in the source
table.</p>
<p><code>JSON.dump</code> is part of the Ruby standard library. All it does is convert the Ruby Hash to a
JSON friendly string, suitable for printing out.</p>

            </div>
            
            <div class="content"><div class='highlight'><pre>output.each <span class="hljs-keyword">do</span> |row|
  datum = {
    <span class="hljs-symbol">company_name:</span> row[<span class="hljs-number">0</span>], 
    <span class="hljs-symbol">company_number:</span> row[<span class="hljs-number">1</span>]
  }

  puts <span class="hljs-constant">JSON</span>.dump(datum) 
<span class="hljs-keyword">end</span></pre></div></div>
            
        </li>
        
    </ul>
  </div>
</body>
</html>
